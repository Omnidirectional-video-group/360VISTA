log_dir: "output/FSRCNN"  # Directory for logs and outputs

dataset:
  train:
    hr_root: "data/train/HR"
    lr_root: "data/train/LR_X4"
    lr_compression_levels: ["0.25M", "0.5M", "1M", "2M"]  # list for Compression levels directories
    crop_size: 64
    transform: True
    batch_size: 4
    shuffle: True
    num_workers: 8
  val:
    hr_root: "data/val/HR"
    lr_root: "data/val/LR_X4"
    lr_compression_levels: ["0.25M", "0.5M", "1M", "2M"]
    batch_size: 4
    shuffle: False
    num_workers: 1
  test:
    hr_root: ''
    lr_root: "data/test/LR_X4"
    lr_compression_levels: ["1"]
    batch_size: 2
    shuffle: False    
    num_workers: 1                       

model:
  path: "src/model/FSRCNN.py"   # Path to the model definition file
  name: "FSRCNN" # Model class name to be instantiated
  scale_factor: 4 # adjust the scale factor

learner:
  general:
    total_steps: 300000000
    log_train_info_steps: 100
    keep_ckpt_steps: 3000
    valid_steps: 500
  optimizer:
    name: "Adam"               # Optimizer type
    lr: 0.0001                 # Learning rate
    beta_1: 0.9
    beta_2: 0.999
  lr_scheduler:
    name: "ExponentialDecay"
    initial_learning_rate: 0.0001
    decay_steps: 10000
    decay_rate: 0.1
    staircase: True
  saver:
    restore: #checkpoints/step_535000_checkpoint_X2_best.pth.tar
  loss:
    name: "CharbonnierLoss"   # Type of loss function to use
    params: {}                # Additional parameters for the loss function, if needed



